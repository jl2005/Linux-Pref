# 综合实战篇

## 系统性能分析

### 使用perf记录

采样30s后退出

```
perf record -a -g -p 9 -- sleep 30
```

### 火焰图分析

```
$ git clone https://github.com/brendangregg/FlameGraph 
$ cd FlameGraph
$ perf script -i ${perf.data} | ./stackcollapse-perf.pl --all |  ./flamegraph.pl > perf.svg
```

其中：

1. 执行 perf script ,将 perf record 的记录转换成可读的采样记录; 
2. 执行 stackcollapse-perf.pl 脚本,合并调用栈信息; 
3. 执行 flamegraph.pl 脚本,生成火焰图。

### 火焰图的分类

* `on-CPU 火焰图`:表示 CPU 的繁忙情况,用在 CPU 使用率比较高的场景中。
* `off-CPU 火焰图`:表示 CPU 等待 I/O、锁等各种资源的阻塞情况。
* `内存火焰图`:表示内存的分配和释放情况。
* `热 / 冷火焰图`:表示将 on-CPU 和 off-CPU 结合在一起综合展示。
* `差分火焰图`:表示两个火焰图的差分情况,红色表示增长,蓝色表示衰减。差分火焰图常用来比较不同场景和不同时期的火焰图,以便分析系统变化前后对性能的影响情况。

## 服务吞吐量下降

## 环境搭建

```
docker run --name nginx --network host --privileged -itd feisky/nginx-tp
docker run --name phpfpm --network host --privileged -itd feisky/php-fpm-tp
```

## 问题复现

```
# wrk --latency -c 1000 -d 1800 http://192.168.57.5
Running 30m test @ http://192.168.57.5
  2 threads and 1000 connections
^C  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.25ms   27.00ms   1.03s    99.88%
    Req/Sec     3.49k   465.24     4.22k    78.78%
  Latency Distribution
     50%    2.11ms
     75%    2.68ms
     90%    3.10ms
     99%    5.24ms
  597636 requests in 2.89m, 123.96MB read
  Socket errors: connect 993, read 0, write 0, timeout 5
Requests/sec:   3451.02
Transfer/sec:    733.00KB
```

本地测试中并没有出现文章中提到请求过慢

## 问题场景

```
# ss -s
Total: 213 (kernel 1178)
TCP:   122 (estab 15, closed 101, orphaned 0, synrecv 0, timewait 101/0), ports 0

Transport Total     IP        IPv6
*         1178      -         -
RAW       2         0         2
UDP       4         3         1
TCP       21        18        3
INET      27        21        6
FRAG      0         0         0
```

发现问题：

1. wrk要求建立1000个连接，但是实际只建立了15
2. close_wait数量太多了

### close wait 数量多


```
# 最大连接跟踪限制
# sysctl net.netfilter.nf_conntrack_max
net.netfilter.nf_conntrack_max = 200


# sysctl net.netfilter.nf_conntrack_count
net.netfilter.nf_conntrack_count = 106
```

本机测试中并没有出现已有连接达到最大连接限制，所以按照文章中的更改，并没有影响结果。


### 分析丢包问题

#### 查看socket情况

```
# netstat -s |grep sock
    9 resets received for embryonic SYN_RECV sockets
    1823 TCP sockets finished time wait in fast timer
    23 delayed acks further delayed because of locked socket
    7987 times the listen queue of a socket overflowed
    7987 SYNs to LISTEN sockets dropped
```

通过对比两次的结果，可以发现监听队列已经满了，并且出现丢包。

#### 查看套接字队列的大小

```
# ss -ltnp
State       Recv-Q Send-Q                              Local Address:Port                                             Peer Address:Port
LISTEN      0      128                                             *:22                                                          *:*                   users:(("sshd",pid=1101,fd=3))
LISTEN      0      100                                     127.0.0.1:25                                                          *:*                   users:(("master",pid=1339,fd=13))
LISTEN      0      10                                              *:80                                                          *:*                   users:(("nginx",pid=13413,fd=6),("nginx",pid=13412,fd=6),("nginx",pid=13411,fd=6))
LISTEN      0      128                                          [::]:22                                                       [::]:*                   users:(("sshd",pid=1101,fd=4))
LISTEN      0      100                                         [::1]:25                                                       [::]:*                   users:(("master",pid=1339,fd=14))
LISTEN      0      10                                           [::]:9000                                                     [::]:*                   users:(("php-fpm",pid=14634,fd=9),("php-fpm",pid=14587,fd=9),("php-fpm",pid=14582,fd=9),("php-fpm",pid=14577,fd=9),("php-fpm",pid=14559,fd=9),("php-fpm",pid=14546,fd=9),("php-fpm",pid=14545,fd=9),("php-fpm",pid=14544,fd=9),("php-fpm",pid=14543,fd=9),("php-fpm",pid=14542,fd=9),("php-fpm",pid=14537,fd=9),("php-fpm",pid=14536,fd=9),("php-fpm",pid=14535,fd=9),("php-fpm",pid=14534,fd=9),("php-fpm",pid=14533,fd=9),("php-fpm",pid=14532,fd=9),("php-fpm",pid=14531,fd=9),("php-fpm",pid=14530,fd=9),("php-fpm",pid=13544,fd=7))
```

#### 查看各个应用backlog的大小

```
# 查询nginx监听队列长度配置
# docker exec nginx cat /etc/nginx/nginx.conf | grep backlog
        listen       80  backlog=10;

# 查询php-fpm监听队列长度
# docker exec phpfpm cat /opt/bitnami/php/etc/php-fpm.d/www.conf | grep backlog
; Set listen(2) backlog.
;listen.backlog = 511
;                          connections (see backlog in listen(2));

# somaxconn是系统级套接字监听队列上限
$ sysctl net.core.somaxconn
net.core.somaxconn = 10
```

以上数字都比较小，需要将nginx 的更新为8192，将系统的更新为65535

#### 系统性能问题

##### 观察日志

```
# 执行perf记录事件
$ perf record -g
# 切换到FlameGraph安装路径执行下面的命令生成火焰图
$ perf script -i ~/perf.data | ./stackcollapse-perf.pl --all | ./flamegraph.pl > nginx.svg
```

#####  定位问题

通过火焰图发现`__init_check_established` 函数占用的CPU最多，由于系统中TIME_WAIT 状态较多，导致这个函数消耗大量时间。

#### 解决方式

通过设置TIME_WAIT端口复用

```
```

疑点：TIME_WAIT 的复用需要进一步的明确利弊，不能粗暴的直接复用。

## 监控方法

USE(Utilization Saturation and Errors)法。USE 法把系统资源的性能指标,简化成了三个类别,即`使用率`、`饱和度`以及`错误数`。

* `使用率`,表示资源用于服务的时间或容量百分比。100% 的使用率,表示容量已经用尽或者全部时间都用于服务。
* `饱和度`,表示资源的繁忙程度,通常与等待队列的长度相关。100% 的饱和度,表示资源无法接受更多的请求。
* `错误数`表示发生错误的事件个数。错误数越多,表明系统的问题越严重。

























